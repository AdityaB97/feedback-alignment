{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size, fashion=False):\n",
    "    mnist = torchvision.datasets.MNIST\n",
    "    if fashion:\n",
    "        mnist = torchvision.datasets.FashionMNIST\n",
    "\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),])\n",
    "\n",
    "    trainloader = th.utils.data.DataLoader(\n",
    "        mnist(root=\"./data\", train=True, download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2)\n",
    "    testloader = th.utils.data.DataLoader(\n",
    "        mnist(root=\"./data\", train=False, download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img href=\"images/linear.png\">\n",
    "We are considering a three-layer network of linear neurons, shown above. The network's output is $\\boldsymbol{y}=W\\boldsymbol{h}$, where $\\boldsymbol{h}$ is the hidden-unit activity vector, given by $\\boldsymbol{h}=W_0\\boldsymbol{x}$, where $\\boldsymbol{x}$ is the input to the network. $W_0$ is the matrix of synaptic weights from $\\boldsymbol{x}$ to $\\boldsymbol{h}$, and $W$ is the weights from $\\boldsymbol{h}$ to $\\boldsymbol{y}$. The network learns to approximate a linear function, $T$ (for 'target'). It's goal is to reduce the squared error, or loss, $\\mathcal{L}=\\frac{1}{2}\\boldsymbol{e}^{T}\\boldsymbol{e}$, where the error $\\boldsymbol{e}=\\boldsymbol{y^*}-\\boldsymbol{y}=T\\boldsymbol{x}-\\boldsymbol{y}$. To train this network, the feedback alignment algorithm adjusts $W$ in the same way as backprop, i.e. $\\Delta W\\propto\\frac{\\partial\\mathcal{L}}{\\partial W}=-\\boldsymbol{e}\\boldsymbol{h}^T$, but for $W_0$, it uses a simpler formula, which needs no information about $W$ or any other synapses, but instead, sends $\\boldsymbol{e}$ through a fixed random matrix $B$:\n",
    "$$\\Delta W_0\\propto B\\boldsymbol{e}\\boldsymbol{x}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target linear function $T$ maps vectors from a $30$- to a $10$-dimensional space, i.e. $T$ has a shape of $10\\times 30$. The elements of $T$ are drawn at random, that is, uniformly, from the range $[-1,1]$. Once chosen, the target matrix is fixed, so that each algorithm (i.e. feedback alignment and backpropagation) tried to learn the same function. Moreover, all algorithms are trained on the same sequence of input/output pairs, with $x\\sim{}\\mathcal{N}(\\mu=0,\\Sigma=I)$, $y^*=Tx$. We have chosen the **number of inputs** to be **100**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear function, inputs, and output generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 100\n",
    "\n",
    "T = np.random.uniform(low=-1.0, high=1.0, size=(10, 30))\n",
    "x_data = np.random.randn(30, num_inputs)\n",
    "y_data = T @ x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_data`: `30 x num_inputs`\n",
    "\n",
    "`y_data`: `10 x num_inputs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights and biases random initalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of $B$ are drawn from the uniform distribution over $[-0.5, 0.5)$, while the elements of the network weight matrix, $W_0$ and $W$, are drawn unifromly from the range $[-0.01,0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.01\n",
    "W0 = np.random.uniform(-a, a, (20, 30))\n",
    "b0 = np.random.uniform(-a, a, 20)\n",
    "\n",
    "W = np.random.uniform(-a, a, (10, 20))\n",
    "b = np.random.uniform(-a, a, 10)\n",
    "\n",
    "a = 0.5\n",
    "B = np.random.uniform(-a, a, (20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data.T, y_data.T, test_size=0.25, shuffle=True)\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "num_epochs = 1000\n",
    "batch_size = 20\n",
    "num_batches = x_train.shape[1] / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_batches, y_train_batches = np.split(x_train, num_batches, axis=1), np.split(y_train, num_batches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Epoch 0\n",
      "      Current loss: 4063.639471419209\n",
      "      Epoch 500\n",
      "      Current loss: 4.54657687026908e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    delta_W0, delta_W, loss = 0, 0, 0\n",
    "    for i in range(len(x_train_batches)):\n",
    "        training_data, training_labels = x_train_batches[i], y_train_batches[i]\n",
    "        \n",
    "        h = W0 @ training_data\n",
    "        y = W @ h\n",
    "        \n",
    "        e = training_labels - y\n",
    "        loss += 0.5 * np.square(np.linalg.norm(e))\n",
    "        \n",
    "        delta_BP = W.T @ e\n",
    "        delta_FA = B @ e\n",
    "        \n",
    "        delta_W = delta_W + e @ h.T\n",
    "        delta_W0 = delta_W0 + B @ e @ training_data.T\n",
    "    \n",
    "    W = W + (eta / (x_train.shape[1])) * delta_W\n",
    "    W0 = W0 + (eta / (x_train.shape[1])) * delta_W0\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"      Epoch {epoch}\")\n",
    "        print(f\"      Current loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.825886652188656e-09"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = W0 @ x_test\n",
    "y = W @ h\n",
    "e = y_test - y\n",
    "test_error = 0.5 * np.square(np.linalg.norm(e))\n",
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "num_epochs = 5\n",
    "batch_size = 20\n",
    "num_batches = (60000) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights and biases random initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.01\n",
    "W0 = np.random.uniform(-a, a, (1000, 784))\n",
    "b0 = np.random.uniform(-a, a, 1000)\n",
    "\n",
    "W = np.random.uniform(-a, a, (10, 1000))\n",
    "b = np.random.uniform(-a, a, 10)\n",
    "\n",
    "a = 0.5\n",
    "B = np.random.uniform(-a, a, (1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(W0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " trainloader, testloader = get_loaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Epoch 0: 100%|██████████| 3000/3000 [00:29<00:00, 121.45it/s]\n",
      "      Epoch 1:   0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Epoch 0\n",
      "      Current loss: 74973.11444391057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Epoch 1: 100%|██████████| 3000/3000 [00:27<00:00, 107.51it/s]\n",
      "      Epoch 2: 100%|██████████| 3000/3000 [00:28<00:00, 106.07it/s]\n",
      "      Epoch 3: 100%|██████████| 3000/3000 [00:26<00:00, 111.34it/s]\n",
      "      Epoch 4: 100%|██████████| 3000/3000 [00:29<00:00, 101.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    delta_W0, delta_W, loss, size = 0, 0, 0, 0\n",
    "    for training_data, training_labels in tqdm(trainloader, desc=f\"      Epoch {epoch}\"):\n",
    "        training_data, training_labels = training_data.view(-1, 784).numpy(), training_labels.numpy()\n",
    "        training_labels = np.reshape(training_labels, newshape=-1)\n",
    "        training_labels = np.eye(10)[training_labels].T\n",
    "        \n",
    "        h = sigma(W0 @ training_data.T)\n",
    "        h = h / np.linalg.norm(h)\n",
    "        y = sigma(W @ h)\n",
    "        e = training_labels - y\n",
    "        loss += 0.5 * np.square(np.linalg.norm(e))\n",
    "        \n",
    "        delta_BP = W.T @ e\n",
    "        delta_FA = B @ e\n",
    "        \n",
    "#         one_y, one_h = np.ones_like(y), np.ones_like(h)\n",
    "        # y' = y * (1 - y)\n",
    "        # h' = h * (1 - h)\n",
    "        \n",
    "        delta_W = delta_W + (e * (y * (1 - y))) @ h.T\n",
    "        delta_W0 = delta_W0 + (delta_FA * h * (1 - h)) @ training_data\n",
    "        \n",
    "        size += training_data.shape[0]\n",
    "    \n",
    "    W = W + eta * delta_W\n",
    "    W0 = W0 + eta * delta_W0\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"      Epoch {epoch}\")\n",
    "        print(f\"      Current loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Layer Non-Linear function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39282.43509643624"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
