{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size, fashion=False):\n",
    "    mnist = torchvision.datasets.MNIST\n",
    "    if fashion:\n",
    "        mnist = torchvision.datasets.FashionMNIST\n",
    "\n",
    "    transform = torchvision.transforms.Compose(\n",
    "        [torchvision.transforms.ToTensor(),])\n",
    "\n",
    "    trainloader = th.utils.data.DataLoader(\n",
    "        mnist(root=\"./data\", train=True, download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2)\n",
    "    testloader = th.utils.data.DataLoader(\n",
    "        mnist(root=\"./data\", train=False, download=True, transform=transform),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img href=\"images/linear.png\">\n",
    "We are considering a three-layer network of linear neurons, shown above. The network's output is $\\boldsymbol{y}=W\\boldsymbol{h}$, where $\\boldsymbol{h}$ is the hidden-unit activity vector, given by $\\boldsymbol{h}=W_0\\boldsymbol{x}$, where $\\boldsymbol{x}$ is the input to the network. $W_0$ is the matrix of synaptic weights from $\\boldsymbol{x}$ to $\\boldsymbol{h}$, and $W$ is the weights from $\\boldsymbol{h}$ to $\\boldsymbol{y}$. The network learns to approximate a linear function, $T$ (for 'target'). It's goal is to reduce the squared error, or loss, $\\mathcal{L}=\\frac{1}{2}\\boldsymbol{e}^{T}\\boldsymbol{e}$, where the error $\\boldsymbol{e}=\\boldsymbol{y^*}-\\boldsymbol{y}=T\\boldsymbol{x}-\\boldsymbol{y}$. To train this network, the feedback alignment algorithm adjusts $W$ in the same way as backprop, i.e. $\\Delta W\\propto\\frac{\\partial\\mathcal{L}}{\\partial W}=-\\boldsymbol{e}\\boldsymbol{h}^T$, but for $W_0$, it uses a simpler formula, which needs no information about $W$ or any other synapses, but instead, sends $\\boldsymbol{e}$ through a fixed random matrix $B$:\n",
    "$$\\Delta W_0\\propto B\\boldsymbol{e}\\boldsymbol{x}^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target linear function $T$ maps vectors from a $30$- to a $10$-dimensional space, i.e. $T$ has a shape of $10\\times 30$. The elements of $T$ are drawn at random, that is, uniformly, from the range $[-1,1]$. Once chosen, the target matrix is fixed, so that each algorithm (i.e. feedback alignment and backpropagation) tried to learn the same function. Moreover, all algorithms are trained on the same sequence of input/output pairs, with $x\\sim{}\\mathcal{N}(\\mu=0,\\Sigma=I)$, $y^*=Tx$. We have chosen the **number of inputs** to be **100**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### linear function, inputs, and output generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 100\n",
    "\n",
    "T = np.random.uniform(low=-1.0, high=1.0, size=(10, 30))\n",
    "x_data = np.random.randn(30, num_inputs)\n",
    "y_data = T @ x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_data`: `30 x num_inputs`\n",
    "\n",
    "`y_data`: `10 x num_inputs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights and biases random initalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of $B$ are drawn from the uniform distribution over $[-0.5, 0.5)$, while the elements of the network weight matrix, $W_0$ and $W$, are drawn unifromly from the range $[-0.01,0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.01\n",
    "W0 = np.random.uniform(-a, a, (20, 30))\n",
    "b0 = np.random.uniform(-a, a, 20)\n",
    "\n",
    "W = np.random.uniform(-a, a, (10, 20))\n",
    "b = np.random.uniform(-a, a, 10)\n",
    "\n",
    "a = 0.5\n",
    "B = np.random.uniform(-a, a, (20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data.T, y_data.T, test_size=0.25, shuffle=True)\n",
    "x_train, x_test, y_train, y_test = x_train.T, x_test.T, y_train.T, y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "num_epochs = 1000\n",
    "batch_size = 20\n",
    "num_batches = x_train.shape[1] / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_batches, y_train_batches = np.split(x_train, num_batches, axis=1), np.split(y_train, num_batches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Epoch 0\n",
      "      Current loss: 4718.910652847859\n",
      "      Epoch 100\n",
      "      Current loss: 0.03493187827713598\n",
      "      Epoch 200\n",
      "      Current loss: 0.0001945607739556033\n",
      "      Epoch 300\n",
      "      Current loss: 2.294901636689887e-06\n",
      "      Epoch 400\n",
      "      Current loss: 3.982002242190957e-08\n",
      "      Epoch 500\n",
      "      Current loss: 8.596120539673434e-10\n",
      "      Epoch 600\n",
      "      Current loss: 2.024267746813628e-11\n",
      "      Epoch 700\n",
      "      Current loss: 4.899382780485309e-13\n",
      "      Epoch 800\n",
      "      Current loss: 1.1942206862273635e-14\n",
      "      Epoch 900\n",
      "      Current loss: 2.913938723654248e-16\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    delta_W0, delta_W, loss = 0, 0, 0\n",
    "    for i in range(len(x_train_batches)):\n",
    "        training_data, training_labels = x_train_batches[i], y_train_batches[i]\n",
    "        \n",
    "        h = W0 @ training_data\n",
    "        y = W @ h\n",
    "        \n",
    "        e = training_labels - y\n",
    "        loss += 0.5 * np.square(np.linalg.norm(e))\n",
    "        \n",
    "        delta_BP = W.T @ e\n",
    "        delta_FA = B @ e\n",
    "        \n",
    "        delta_W = delta_W + e @ h.T\n",
    "        delta_W0 = delta_W0 + B @ e @ training_data.T\n",
    "    \n",
    "    W = W + (eta / (x_train.shape[1])) * delta_W\n",
    "    W0 = W0 + (eta / (x_train.shape[1])) * delta_W0\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"      Epoch {epoch}\")\n",
    "        print(f\"      Current loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1185654454575129e-17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = W0 @ x_test\n",
    "y = W @ h\n",
    "e = y_test - y\n",
    "test_error = 0.5 * np.square(np.linalg.norm(e))\n",
    "test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear function approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.1\n",
    "num_epochs = 1000\n",
    "batch_size = 20\n",
    "num_batches = (60000) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights and biases random initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.1\n",
    "W0 = np.random.uniform(-a, a, (1000, 784))\n",
    "b0 = np.random.uniform(-a, a, 1000)\n",
    "\n",
    "W = np.random.uniform(-a, a, (10, 1000))\n",
    "b = np.random.uniform(-a, a, 10)\n",
    "\n",
    "a = 0.5\n",
    "B = np.random.uniform(-a, a, (1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(W0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1244b0358>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Test dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " trainloader, testloader = get_loaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch 0:   0%|          | 0/3000 [00:00<?, ?it/s]\u001b[A\n",
      "      Epoch 0:   0%|          | 5/3000 [00:00<01:00, 49.35it/s]\u001b[A\n",
      "      Epoch 0:   1%|          | 17/3000 [00:00<00:50, 59.60it/s]\u001b[A\n",
      "      Epoch 0:   1%|          | 29/3000 [00:00<00:42, 69.29it/s]\u001b[A\n",
      "      Epoch 0:   1%|▏         | 41/3000 [00:00<00:37, 78.43it/s]\u001b[A\n",
      "      Epoch 0:   2%|▏         | 53/3000 [00:00<00:34, 86.62it/s]\u001b[A\n",
      "      Epoch 0:   2%|▏         | 65/3000 [00:00<00:31, 93.07it/s]\u001b[A\n",
      "      Epoch 0:   3%|▎         | 77/3000 [00:00<00:29, 98.10it/s]\u001b[A\n",
      "      Epoch 0:   3%|▎         | 89/3000 [00:00<00:28, 102.98it/s]\u001b[A\n",
      "      Epoch 0:   3%|▎         | 101/3000 [00:00<00:27, 106.36it/s]\u001b[A\n",
      "      Epoch 0:   4%|▎         | 112/3000 [00:01<00:27, 103.32it/s]\u001b[A\n",
      "      Epoch 0:   4%|▍         | 123/3000 [00:01<00:29, 98.07it/s] \u001b[A\n",
      "      Epoch 0:   4%|▍         | 135/3000 [00:01<00:28, 102.30it/s]\u001b[A\n",
      "      Epoch 0:   5%|▍         | 147/3000 [00:01<00:27, 105.36it/s]\u001b[A\n",
      "      Epoch 0:   5%|▌         | 159/3000 [00:01<00:26, 107.44it/s]\u001b[A\n",
      "      Epoch 0:   6%|▌         | 170/3000 [00:01<00:26, 107.54it/s]\u001b[A\n",
      "      Epoch 0:   6%|▌         | 182/3000 [00:01<00:25, 109.34it/s]\u001b[A\n",
      "      Epoch 0:   6%|▋         | 193/3000 [00:01<00:26, 106.16it/s]\u001b[A\n",
      "      Epoch 0:   7%|▋         | 204/3000 [00:01<00:26, 104.36it/s]\u001b[A\n",
      "      Epoch 0:   7%|▋         | 216/3000 [00:02<00:25, 107.36it/s]\u001b[A\n",
      "      Epoch 0:   8%|▊         | 227/3000 [00:02<00:27, 102.52it/s]\u001b[A\n",
      "      Epoch 0:   8%|▊         | 238/3000 [00:02<00:26, 102.40it/s]\u001b[A\n",
      "      Epoch 0:   8%|▊         | 249/3000 [00:02<00:27, 100.35it/s]\u001b[A\n",
      "      Epoch 0:   9%|▊         | 260/3000 [00:02<00:30, 90.85it/s] \u001b[A\n",
      "      Epoch 0:   9%|▉         | 270/3000 [00:02<00:30, 89.61it/s]\u001b[A\n",
      "      Epoch 0:   9%|▉         | 281/3000 [00:02<00:28, 94.52it/s]\u001b[A\n",
      "      Epoch 0:  10%|▉         | 291/3000 [00:02<00:32, 82.41it/s]\u001b[A\n",
      "      Epoch 0:  10%|█         | 300/3000 [00:03<00:33, 80.26it/s]\u001b[A\n",
      "      Epoch 0:  10%|█         | 309/3000 [00:03<00:34, 78.78it/s]\u001b[A\n",
      "      Epoch 0:  11%|█         | 318/3000 [00:03<00:33, 79.59it/s]\u001b[A\n",
      "      Epoch 0:  11%|█         | 327/3000 [00:03<00:34, 78.39it/s]\u001b[A\n",
      "      Epoch 0:  11%|█         | 335/3000 [00:03<00:34, 78.38it/s]\u001b[A\n",
      "      Epoch 0:  12%|█▏        | 345/3000 [00:03<00:31, 83.65it/s]\u001b[A\n",
      "      Epoch 0:  12%|█▏        | 356/3000 [00:03<00:29, 89.90it/s]\u001b[A\n",
      "      Epoch 0:  12%|█▏        | 366/3000 [00:03<00:28, 92.54it/s]\u001b[A\n",
      "      Epoch 0:  13%|█▎        | 377/3000 [00:03<00:27, 96.49it/s]\u001b[A\n",
      "      Epoch 0:  13%|█▎        | 387/3000 [00:03<00:28, 92.46it/s]\u001b[A\n",
      "      Epoch 0:  13%|█▎        | 397/3000 [00:04<00:30, 86.19it/s]\u001b[A\n",
      "      Epoch 0:  14%|█▎        | 406/3000 [00:04<00:30, 86.32it/s]\u001b[A\n",
      "      Epoch 0:  14%|█▍        | 416/3000 [00:04<00:28, 89.22it/s]\u001b[A\n",
      "      Epoch 0:  14%|█▍        | 427/3000 [00:04<00:27, 93.79it/s]\u001b[A\n",
      "      Epoch 0:  15%|█▍        | 437/3000 [00:04<00:27, 91.89it/s]\u001b[A\n",
      "      Epoch 0:  15%|█▍        | 447/3000 [00:04<00:28, 89.95it/s]\u001b[A\n",
      "      Epoch 0:  15%|█▌        | 457/3000 [00:04<00:28, 88.57it/s]\u001b[A\n",
      "      Epoch 0:  16%|█▌        | 466/3000 [00:04<00:29, 87.37it/s]\u001b[A\n",
      "      Epoch 0:  16%|█▌        | 475/3000 [00:04<00:28, 87.25it/s]\u001b[A\n",
      "      Epoch 0:  16%|█▌        | 484/3000 [00:05<00:28, 87.34it/s]\u001b[A\n",
      "      Epoch 0:  16%|█▋        | 495/3000 [00:05<00:27, 91.80it/s]\u001b[A\n",
      "      Epoch 0:  17%|█▋        | 505/3000 [00:05<00:27, 92.01it/s]\u001b[A\n",
      "      Epoch 0:  17%|█▋        | 515/3000 [00:05<00:27, 89.38it/s]\u001b[A\n",
      "      Epoch 0:  17%|█▋        | 524/3000 [00:05<00:28, 85.65it/s]\u001b[A\n",
      "      Epoch 0:  18%|█▊        | 533/3000 [00:05<00:29, 84.69it/s]\u001b[A\n",
      "      Epoch 0:  18%|█▊        | 542/3000 [00:05<00:29, 84.75it/s]\u001b[A\n",
      "      Epoch 0:  18%|█▊        | 551/3000 [00:05<00:28, 84.55it/s]\u001b[A\n",
      "      Epoch 0:  19%|█▊        | 560/3000 [00:05<00:28, 84.43it/s]\u001b[A\n",
      "      Epoch 0:  19%|█▉        | 569/3000 [00:06<00:28, 84.18it/s]\u001b[AProcess Process-269:\n",
      "Process Process-270:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\", line 920, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/usr/local/Cellar/python/3.7.1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x116f36d90>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 397, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 22456) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d3918c9ab38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdelta_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_W\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdelta_W0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_W0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta_FA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mone_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    delta_W0, delta_W, loss, size = 0, 0, 0, 0\n",
    "    for training_data, training_labels in tqdm(trainloader, desc=f\"      Epoch {epoch}\"):\n",
    "        training_data, training_labels = training_data.view(-1, 784).numpy(), training_labels.numpy()\n",
    "        training_labels = np.reshape(training_labels, newshape=-1)\n",
    "        training_labels = np.eye(10)[training_labels].T\n",
    "        \n",
    "        h = sigma(W0 @ training_data.T)\n",
    "        y = sigma(W @ h)\n",
    "        e = training_labels - y\n",
    "        loss += 0.5 * np.square(np.linalg.norm(e))\n",
    "        \n",
    "        delta_BP = W.T @ e\n",
    "        delta_FA = B @ e\n",
    "        \n",
    "        one_y, one_h = np.ones_like(y), np.ones_like(h)\n",
    "        \n",
    "        delta_W = delta_W + (e * (y * (one_y - y))) @ h.T\n",
    "        delta_W0 = delta_W0 + (delta_FA * (h * (one_h - h))) @ training_data\n",
    "        \n",
    "        size += training_data.shape[0]\n",
    "    \n",
    "    W = W + (eta / size) * delta_W\n",
    "    W0 = W0 + (eta / size) * delta_W0\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"      Epoch {epoch}\")\n",
    "        print(f\"      Current loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Layer Non-Linear function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
